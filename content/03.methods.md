## Methods {.page_break_before}
### Data Collection
To measure the accuracy of our method, we only used data that had already been manually identified as related. To achieve this
we used the Search Tag Analyze Resource for GEO application (StarGEO). StarGEO is a collection of datasets from the Gene Expression Omnibus that have manually annotated 
by biomedical graduate students to facilitate the task of collecting related datasets [@doi:10.1038/sdata.2017.125]. For each entry in StarGEO the dataset has an abstract, 
title, and Gene Expression Omnibus accession number.
Each dataset in StarGEO has been hand curated and attached to several tags that seek to categorize on a broad level the type of data encapsulated [@doi:10.1038/sdata.2017.125].
To ensure a mixture of broad and narrow queries, as well as different domains, we selected six queries to test. Two of which are broad with 50+ articles returned, two are medium with 20-50 articles returned and two are small with
 less than 10 articles returned. These queries cover a wide range of domains. It is important to to note that since StarGEO is an
ongoing project, it is likely that these queries currently have more articles than at the time of writing.

| *Keywords* | *Number of Articles Returned by StarGeo* |
|:-----------|:----------------------------------------:|
| Cancer + Brain                       | 53|
| SARS                                 | 52|
| H1n1 + Infection + Mouse + Lethal    | 8 |
| Acute_Leukemia + MLL + Progression   | 10|
| BRCA + Cancer                        | 20|
| Heart Development + Age + Failure    | 28|
The purpose of widely varying the amount of articles returned is to ensure that our method works for narrowly defined topics as well as broad topics as well as to test the difference. All data
accession was performed using the StarGEO API [@url:http://stargeo.org/api_docs/]. The API was accessed and stored in a dictionary keyed by accession number to combined abstract and title.

### Model Collection
Once the data was collected the next step was identifying the techniquesResearch has already shown that a variety of natural language processing models are effective on biomedical literature [@doi:10.18653/v1/W16-2922; @doi:10.1016/j.jbi.2018.09.008].
However we felt it was necessary to test a variety of techniques for both keyword extraction and word vector generation to identify the combination most
suited to our unique task.

Keyword Identification is the first step that our data in the dictionary goes through. To accomplish quick querying in a standardized framework we sued the PKE package available
in Python. All documentation is available on GitHub [@url:https://github.com/boudinfl/pke]. The PKE packages allowed us to use one single package to access all the keyword embedding 
techniques, instead of individually querying each technique. The keyword extraction techniques that were tested are the following: TFIDF, KPMiner, YAKE, TextRank, SingleRank, 
TopicRank, TopicalPageRank, PositionRank and MultipartiteRank [@url:https://github.com/boudinfl/pke]. Using each of these techniques keywords were identified from the target text. 
Each of these techniques is technologically diverse and we chose them due to the expectation that the techniques would yield different keywords. 

After the keywords have been identified from the target text, word vectors are generated from each keyword using a word vector model. These models use large amounts
of unlabeled text to identify the meanings of words and express those as a numeric vector. For our project we selected 6 different models that encompass a variety of techniques 
and training data. The two major frameworks used in this project were Spacy and FastText. These models are the two most widely used frameworks in natural language processing
and both have been used in biomedical applications [@doi:10.1038/s41598-019-47046-2; @doi:10.1186/s12859-018-2496-4; @doi:10.18653/v1/W16-2922]. However there are differences 
in how these models train on sample text and generate word vectors. For these reason we chose to test both platforms. 

The source of training data is an important aspect of generating word vectors. Recent literature supports matching the training data to the testing data [@doi:10.18653/v1/W16-2922]. 
However the benefit of keeping the training and testing data in the same domain is not supported in all the literature [@doi:10.1016/j.jbi.2018.09.008]. To test this effect we have 
models trained on both biomedical literature and other sources such as web blogs, news, and Wikipedia [@url:https://arxiv.org/abs/1607.04606]. This training data has several 
possible algorithms for processing and generating word vectors. The two majors options are Continuous-Bag-Of-Words (CBOW) and SKIPGRAM, a complete explanation of these algorithms
is outside the scope of this paper. Both of these algorithms have been shown effective on biomedical natural language processing, but small differences have been shown between the
word vectors generated from either algorithm [@doi:10.1371/journal.pone.0220976]. Due to this, both algorithms are tested. There are a total of 6 models tested in this paper. FastText
and Spacy are compared head to head, as well as different algorithms and training data. A summary of each model and brief details are shown below. 

| *Model* | *Summary* |
|:--------|:---------:|
| BioWordVec        | FastText Model trained on generic biomedical data with SKIPGRAM   |
| FastTextWiki      | FastText model trained on Wikipedia data with CBOW                |
| FastTextCBOW      | FastText model trained on GEO data using CBOW                     |
| FastTextSKIPGRAM  | FastText model trained on GEO data using SKIPGRAM                 |
| SciSpacy          | A Spacy model designed for usage in biomedical applications       |
| SpacyWebLG        | A Spacy model desined for generic usage                           |

### Vector Generation
The initial step of vector generation is the identification of the top ten keywords from the text source. Each one of these keywords is turned into a word vector. This word vector is
stored as a list of numeric values. The models vary in the length of this numeric vectors from 100 - 300. Once each vector has been generated from each keyword these vectors are added 
element-wise and then divided by the number of keywords. This technique has been shown to be the simplest and most accurate way to generate a singular word vector from various word 
embeddings and is usually used to generate document-wide word embeddings [@url:http://arxiv.org/abs/1607.05368].

### Manual Gene Expression Omnibus Evaluation
Gene Expression Omnibus (GEO) is the parent corpus from which StarGEO is derived [@doi:10.1093/nar/30.1.207]. To compare our technique directly to GEO we use a manual technique. We first use the advanced search option on 
GEO to input the exact queries we used from StarGEO. 

### Model Evaluation 
All model evaluation is performed in a Docker container to allow other researchers to perform the same analysis described in this section [@doi:10.1145/2723872.2723882].The Docker image 
used to build the container is the python:3.8.5 image available on the Docker website [@url:https://hub.docker.com/_/python]. In the 'Python_Code' directory there are six scripts that handle
each of the models. Each script performs the following steps:
1. Queries StarGEO to get all abstracts and titles, stores all of this data inside a dictionary
2. Loads the specific model, this is dependent on which model is being tested
3. For each query (of 5) a job is started using the Multiprocessing package for each keyword embedding method, these are all ran as a pool
4. Each job in the pool performs the following steps
    i. For the specified query the code access a filesystem that contains all the articles for each query
    ii. Half of the possible articles are randomly selected as the training corpus. In the exploratory analysis we did for this project we initially used three articles from each query. However we moved away from this because
    three random articles have a high chance of choosing 3 articles that do not cover the full breadth of the query. Likewise if one of those three articles is covers a niche topic that may be peripherally related to the 
    query that will greatly affect the performance in identifying a broader query. 
    iii. A predetermined number of keywords (10,20,30) is identified from each article
    iv. a word vector for each keyword is created, these are then numerically added and divided by the number of keywords
    v. The vectors from the training corpus are numerically added and divided by 3, this is referred to as the test vector
    vi. This process of keyword identification and vector generation are repeated for each article queried from StarGEO
    vii. The cosine similarity between the test vector and each article is calculated and printed to a file
5. The most similar 1,10,100,1000 articles are analyzed to see what percentage of the relevant articles were found for each query



