## Methods {.page_break_before}

### Data collection

As a reference standard, we used annotations from Search Tag Analyze Resource for GEO (STARGEO)[@doi:10.1038/sdata.2017.125]. In STARGEO, biomedical graduate students manually curate sample metadata and assign tags to GEO series. We used these annotations to identify series that had been associated with a given phenotype. To represent different types of queries that researchers might perform in GEO, we searched for human phenotypes that would result in a small, medium, or large number of GEO series. We also sought to represent diverse phenotypic categories. On XX[TODO: Please indicate exact or approximate date], we identified two phenotypes with ~100 series, two with ~20 series, and two with fewer than 10 series[Table @tbl:query-summary]. (Because STARGEO is an ongoing project, it is likely that additional articles will be associated with these tags over time.) For each GEO series, we used the STAR application programming interface[@url:http://STARGEO.org/api_docs/] to download the associated abstract, title, and accession number. 

| *STARGEO tag(s)*               | *Number of GEO series*  |
|:-------------------------------|------------------------:|
| Family History + Breast Cancer |                       6 |
| Liver Damage + Hepatitis       |                       9 |
| Monozygotic Twins              |                      25 |
| Kidney + Tumor + Cell Line     |                      16 |
| Diabetes + Type 1              |                      97 |
| Osteosarcoma                   |                     112 |

Table: Caption for this example table. {#tbl:query-summary}

### Keyphrase extraction

[TODO: Please move the following sentence to the Introduction if these papers are not already mentioned there. Also, make sure we are describing how these models were used and briefly what the authors found.] A variety of natural language processing models are effective on biomedical literature [@doi:10.18653/v1/W16-2922; @doi:10.1016/j.jbi.2018.09.008].

For each abstract, we sought to identify *n* keyphrases that would most effectively characterize the semantic meaning of the abstract. In our benchmark comparisons, we used *n* values of 10, 20, and 30 and applied nine unsupervised, keyphrase-extraction techniques to each abstract. To ensure consistency across the techniques, we used the pke Python module[https://aclanthology.org/C16-2015/] for all nine techniques, which were TFIDF[@https://ieeexplore.ieee.org/abstract/document/5392697;@https://www.emerald.com/insight/content/doi/10.1108/eb026526/full/html], KP-Miner[@http://www.aclweb.org/anthology/S10-1041.pdf], YAKE[@https://doi.org/10.1016/j.ins.2019.09.013], TextRank[@http://www.aclweb.org/anthology/W04-3252.pdf], SingleRank[@http://www.aclweb.org/anthology/C08-1122.pdf], TopicRank[@http://aclweb.org/anthology/I13-1062.pdf], TopicalPageRank[@http://users.intec.ugent.be/cdvelder/papers/2015/sterckx2015wwwb.pdf], PositionRank[@http://www.aclweb.org/anthology/P17-1102.pdf] and MultipartiteRank[https://arxiv.org/abs/1803.08721]. These techniques uses different algorithmic approaches. [TODO: Will you please clarify what the following sentence is referring to. Is there a specific data file?]An example of the diversity of returned keywords is available in the appendix.

### Word-vector models

Using keyphrases from each abstract, we generated word vectors---numeric representations of the text---based on models that had previously been trained on large amounts of unlabeled text. We generated the word vectors using the *fastText* (version X.XX[TODO: specify version]) and *spaCy* (version Y.Y[TODO: specify version]) open-source libraries [@url:https://spacy.io;@arxiv:1902.07669;@arXiv:1607.04606], which both have been used widely in biomedical applications [@doi:10.1038/s41598-019-47046-2; @doi:10.1186/s12859-018-2496-4; @doi:10.18653/v1/W16-2922] and differ in their methodologies. fastText provides two approaches for generating word vectors: Skip-gram and Continuous-Bag-Of-Words (CBOW). Given a particular word (or subword), the Skip-gram method trains a neural network to predict surrounding (sub)words; the weights of the network's hidden layer are used in the word vector. The CBOW method uses a similar approach but attempts to predict a (sub)word of interest, given a fixed-size window of surrounding (sub)words. For spaCy, we used named-entity recognition models with tokenized, hashed representations constructed from word features[@https://arxiv.org/pdf/1902.07669.pdf].[TODO: Please check this wording against what you understand.] We generated a word vector for each keyphrase, summed the vectors for a given abstract, and then divided by the number of keywords in the abstract (as a form of standardization). This technique has been shown to be a simple and accurate way to combine multiple embeddings into a single vector and is often used to generate document-level embeddings [@url:http://arxiv.org/abs/1607.05368].
%https://towardsdatascience.com/word2vec-skip-gram-model-part-1-intuition-78614e4d6e0b

"FastText [8] expresses a word by the sum of the N-gram vector of the character level. The embedding method at the subword level solves the disadvantages that involve difficulty in application to languages with varying morphological changes or low frequency. This method was strong at solving the OOV problem, and accuracy was high for rare words in the word set. BioWordVec [9] learns clinical record data from PubMed and MIMIC-III clinical databases using fastText. Based on 28,714,373 PubMed documents and 2,083,180 MIMIC-III clinical database documents, the entire corpus was built. The Medical Subject Headings (MeSH) term graph was organized to create a heading sequence and to carry out word embedding based on a sequence combining MeSH and PubMed. BioWordVec provided a 200-dimensional pretrained word embedding matrix"

[TODO: Please move this to the Introduction.] Both of these algorithms have been shown effective on biomedical natural language processing, but [TODO: this wording is vague. Please add some details to make it concrete.]small differences have been shown between the word vectors generated from either algorithm [@doi:10.1371/journal.pone.0220976].

### Training corpora

[TODO: Please move these ideas to the Introduction or Discussion.] The source of the training data is an important aspect of generating word vectors. Recent literature supports using training data from a research domain that matches the domain of the testing data [@doi:10.18653/v1/W16-2922]. However, the benefits of using domain-specific training data remain under question [@doi:10.1016/j.jbi.2018.09.008].

We used models that had been pre-trained on text from diverse sources. The BioWordVec model[@pubmed:31076572] was trained on PubMed abstracts and clinical notes from the MIMIC-III database[@https://www.nature.com/articles/sdata201635] (downloaded from https://ftp.ncbi.nlm.nih.gov/pub/lu/Suppl/BioSentVec/). It uses fastText to encode and summarize n-gram representations of words in 200-dimensional word-embedding matrix.

To test this effect we trained models on biomedical literature as well as general sources such as blogs, news articles, and Wikipedia entries [@url:https://arxiv.org/abs/1607.04606].

Depending on the model, the word vectors differed in length between 100 and 300. [TODO: Please indicate the vector length for each model and a brief explanation of why we used different lengths.] 

Emphasize that we used English corpora.

This training data has several possible algorithms for processing and generating word vectors. There are a total of 6 models tested in this paper. fastText and Spacy are compared head to head, as well as different algorithms and training data. A summary of each model and brief details are shown below. 

A spaCy NER model trained on the BC5CDR corpus.

| *Model* | *Summary* |
|:--------|:---------|
| BioWordVec        | fastText Model trained on generic biomedical data with Skip-gram    |
| FastTextWiki      | fastText model trained on Wikipedia data with CBOW                 |
| FastTextSKIPGRAM  | fastText model trained on GEO data using Skip-gram                  |
| FastTextCBOW      | fastText model trained on GEO data using CBOW                      |
| SciSpacy          | A Spacy model trained on biomedical data                           |
| SpacyWebLG        | A Spacy model trained on general Web text ((blogs, news, comments) |

### Model Evaluation 
 
We tested each combination of keyword extraction and word-vector generation method...

All model evaluation is performed in a Docker container to allow other researchers to perform the same analysis described in this section [@doi:10.1145/2723872.2723882].The Docker image 
used to build the container is the python:3.8.5 image available on the Docker website [@url:https://hub.docker.com/_/python]. Running the docker container as pulled from github will run a bash script that performs the following
steps. 
    1. STARGEO is queried to prepare the six queries. The prepareQueryData.py script takes two arguments. The first is a list of GEO identifiers and the second is the query number that these identifiers
    should belong to. PrepareQueryData.py creates a file system that contains all the abstract and titles of the series that correspond to each identifier. The file system will put each text file into the directory for the corresponding
    query. This script also randomly selects half of the data to be used as the training data. 
    2. GetGeoQueries.py is run. This script uses text files generated by GEO to evaluate the performance of GEO. A detailed explanation of this is found below in the manual comparision section.
    3. A do loop iterates over the numbers 10,20, and 30. This numbers are the number of keywords that each model should try to identify from the text. Each iteration performs the following analysis.
        i. Six scripts that correspond to SciSpaCy, BioWordVec, FastTextWiki, SpaCy, FastTextSkipGram, and FastTextCBOW are run. Each of these scripts takes the following three arguments : number of keywords, vector size, and number of STARGEO articles. Each script performs the following steps:
            a. All candidate articles from STARGEO are queried
            b. The specific word vector model is loaded (SciSpaCy, BioWordVec, ...)
            c. For each query and keyword combination findSimilarity() is run in Helper.py and added to a multiprocessing thread. This script prints to an output file the calculated similarity of each article using each combination
            d. The top 1,10 and 100 articles are returned to compare against the articles that STARGEO previously identified as related. 

### Reduced Set Testing

The results contained within this paper are from a reduced set of all STARGEO articles (266) plus an additional 1000 randomly queried articles from GEO. The purpose for performing the reduced set was the full 41,823 article corpus from STARGEO
ran for over one month and we were not able to complete the full testing. A reduced corpus of 1000 articles allowed us to compare the various methods head to head without the need for extensively long wait times. However the analysis is set up 
in such a way as to allow the researcher to easily change the amount of articles used in the analysis. 

### Manual Gene Expression Omnibus Evaluation

Gene Expression Omnibus (GEO) is the parent corpus from which STARGEO is derived [@doi:10.1093/nar/30.1.207]. To compare our technique directly to GEO we use a manual evaluation. We first use the advanced search option on 
GEO to input the exact queries we used from STARGEO. To maintain consistency with STARGEO, the results are limited to series and human genomic data. A summary file of all the results is downloaded and analyzed. To ensure equal comparision
the results are filtered to only include those datasets that exist in STARGEO's corpus while excluding SuperSeries. Using the same technique for the STARGEO evaluation the top 1,10, and 100 articles are identified and compared against the relevant articles 
from STARGEO.  

